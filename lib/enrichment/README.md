# ğŸ¤– Property Enrichment System

AI-powered data enrichment for real estate properties using OpenAI GPT-4o-mini.

## ğŸ“‹ Overview

This system automatically extracts and structures data from property listings to improve search quality and data consistency.

### What It Does

Transforms messy, unstructured property data like this:

```json
{
  "title": "Apartamento com 3 Quartos para Alugar em JundiaÃ­",
  "description": "Lindo apartamento...",
  "property_type": null,
  "bedrooms": null,
  "address_neighborhood": null,
  "features": []
}
```

Into clean, structured data like this:

```json
{
  "property_type": "apartamento",
  "listing_type": "rent",
  "bedrooms": 3,
  "bathrooms": 2,
  "parking_spaces": 1,
  "address_neighborhood": "Centro",
  "features": ["piscina", "academia", "churrasqueira"],
  "ai_summary": "Apartamento de 3 quartos no Centro de JundiaÃ­..."
}
```

## ğŸš€ Quick Start

### 1. Validate Current Data Quality

Check how much of your data needs enrichment:

```bash
pnpm validate
```

Example output:
```
ğŸ“Š DATA QUALITY VALIDATION REPORT
Total Active Properties: 582
  AI Summary:          45 / 582 (7.7%)
  Property Type:       430 / 582 (73.9%)
  Neighborhood:        2 / 582 (0.3%)

OVERALL QUALITY SCORE: 42/100
âš ï¸ Poor data quality. Enrichment highly recommended!
```

### 2. Test Enrichment (Dry Run)

Test on 3 properties without saving:

```bash
pnpm enrich:test
```

### 3. Run Full Enrichment

Process all properties:

```bash
pnpm enrich
```

Advanced options:

```bash
# Process only 50 properties
pnpm enrich -- --limit=50

# Only enrich properties missing summaries
pnpm enrich -- --missing-summary

# Force re-enrich all properties
pnpm enrich -- --force

# Dry run on 100 properties
pnpm enrich -- --dry-run --limit=100

# Custom batch size and delay
pnpm enrich -- --batch-size=10 --delay=2000
```

## ğŸ“ File Structure

```
lib/enrichment/
â”œâ”€â”€ types.ts           # TypeScript type definitions
â”œâ”€â”€ parser.ts          # OpenAI-powered parsing logic
â”œâ”€â”€ auto-enrich.ts     # Automatic enrichment for new properties
â””â”€â”€ README.md          # This file

scripts/
â”œâ”€â”€ enrich-properties.ts      # Batch enrichment script
â””â”€â”€ validate-enrichment.ts    # Data quality validation

app/api/properties/enrich/
â””â”€â”€ route.ts           # API endpoint for on-demand enrichment
```

## ğŸ”§ How It Works

### Batch Enrichment (scripts/enrich-properties.ts)

1. **Fetch** properties needing enrichment from Supabase
2. **Process** in batches of 5 (configurable) using OpenAI
3. **Extract** structured data from title + description
4. **Validate** extracted data (enums, numbers, etc.)
5. **Save** to database
6. **Report** stats and estimated cost

**Cost**: ~$0.0001 per property with GPT-4o-mini
**Time**: ~10-15 minutes for 100 properties (with rate limiting)

### Automatic Enrichment (lib/enrichment/auto-enrich.ts)

Called automatically when new properties are added:

```typescript
import { autoEnrichProperty } from '@/lib/enrichment/auto-enrich'

// After inserting a new property
await autoEnrichProperty(newProperty.id)
```

Or via API:

```bash
curl -X POST http://localhost:3000/api/properties/enrich \
  -H "Content-Type: application/json" \
  -d '{"propertyId": "uuid-here"}'
```

## ğŸ¯ What Gets Extracted

### Critical Fields (Always Extracted)
- `property_type` - apartamento, casa, sobrado, etc.
- `listing_type` - rent or sale
- `ai_summary` - 2-3 sentence summary in Portuguese

### Important Fields (When Available)
- `bedrooms` - Number of bedrooms
- `bathrooms` - Number of bathrooms
- `suites` - Number of suites (bedrooms with private bathroom)
- `parking_spaces` - Number of parking spots
- `address_neighborhood` - Neighborhood name

### Financial Fields
- `price_monthly` - Monthly rental price
- `price_total` - Total sale price
- `condominium_fee` - Monthly condo fee
- `iptu_monthly` / `iptu_annual` - Property tax

### Additional Data
- `furnished` - furnished, unfurnished, semi_furnished
- `features` - Array of amenities (piscina, academia, etc.)

## ğŸ“Š Data Quality Metrics

The validation script calculates a quality score (0-100) based on:

- **AI Summary** (25 weight) - Critical for search and display
- **Property Type** (20%) - Essential for filtering
- **Listing Type** (15%) - Rent vs sale classification
- **Bedrooms** (15%) - Important search criterion
- **Neighborhood** (15%) - Key location data
- **Features** (10%) - Nice-to-have amenities

**Quality Levels:**
- 90-100: Excellent (production-ready)
- 70-89: Good (minor improvements needed)
- 50-69: Moderate (enrichment recommended)
- 0-49: Poor (enrichment required)

## ğŸ”„ Workflow Integration

### For New Properties (Future Scraper Integration)

Add enrichment to your property ingestion pipeline:

```typescript
// In your scraper/import script
import { autoEnrichProperty } from '@/lib/enrichment/auto-enrich'

const newProperty = await supabase.from('properties').insert({
  source_url: url,
  title: scrapedTitle,
  description: scrapedDescription,
  // ... other fields
}).select().single()

// Automatically enrich
await autoEnrichProperty(newProperty.id)
```

### Background Job (Optional)

For continuous enrichment, set up a cron job:

```typescript
// Example: Vercel Cron or similar
export async function GET() {
  // Find unenriched properties
  const { data } = await supabase
    .from('properties')
    .select('id')
    .is('ai_summary', null)
    .limit(50)
  
  // Enrich them
  await autoEnrichProperties(data.map(p => p.id))
  
  return Response.json({ enriched: data.length })
}
```

## âš ï¸ Important Notes

### Environment Variables Required

```env
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
OPENAI_API_KEY=your_openai_key
```

### Rate Limiting

The batch script includes built-in delays (default: 1000ms between batches) to avoid hitting OpenAI rate limits.

### Token Usage

- Average: ~500 tokens per property
- Cost: ~$0.0001 per property (GPT-4o-mini)
- Very affordable for large-scale enrichment

### Data Validation

All extracted data is validated before saving:
- Enums are checked against allowed values
- Numbers are parsed and validated
- Arrays are deduplicated and cleaned
- Missing fields default to `null`

## ğŸ› Troubleshooting

### "Missing OPENAI_API_KEY"
Make sure your `.env.local` file has the OpenAI API key set.

### "Empty response from OpenAI"
Rare error - the script will retry or you can re-run with the failed property IDs.

### "Property already enriched, skipping"
The script only enriches properties missing `ai_summary` by default. Use `--force` to re-enrich.

### Rate limit errors
Increase the delay: `pnpm enrich -- --delay=2000`

## ğŸ“ˆ Expected Results

After running enrichment, you should see:

**Improvements:**
- AI Summary: â†’ 100%
- Property Type: â†’ 100%
- Neighborhood: â†’ 90%+
- Features: â†’ 90%+
- Quality Score: â†’ 90+/100

This will dramatically improve:
- âœ… Search accuracy
- âœ… Property matching quality
- âœ… Data consistency
- âœ… User experience

**Note:** Images are not part of the enrichment process. The system focuses on structured data extraction and AI-generated summaries.

## ğŸ¯ Next Steps

1. Run `pnpm validate` to check current quality
2. Run `pnpm enrich:test` to test on 3 properties
3. Review results, then run full enrichment
4. Integrate auto-enrichment into your scraper
5. Set up validation as part of CI/CD

---

**Questions?** Check the code comments in:
- `lib/enrichment/parser.ts` - Core enrichment logic
- `scripts/enrich-properties.ts` - Batch processing
- `lib/enrichment/auto-enrich.ts` - Auto-enrichment
